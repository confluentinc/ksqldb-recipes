<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Clickstream Data Analysis - ksqlDB Recipes</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../../css/theme.css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "Clickstream Data Analysis";
    var mkdocs_page_input_path = "customer-360/clickstream/index.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> ksqlDB Recipes</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../..">ksqlDB Recipes</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Ai ml</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../ai-ml/">Description</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Customer 360</span></p>
                <ul class="current">
                    <li class="toctree-l1"><a class="reference internal" href="../">Description</a>
                    </li>
                    <li class="toctree-l1 current"><a class="reference internal current" href="#">Clickstream</a>
    <ul class="current">
                <li class="toctree-l2 current"><a class="reference internal current" href="./">Clickstream Data Analysis</a>
    <ul class="current">
    <li class="toctree-l3"><a class="reference internal" href="#what-is-it">What is it?</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#cut-to-the-code">Cut to the code</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#launch-step-by-step">Launch Step-by-Step</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#setup-your-environment">Setup your Environment</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#read-the-data-in">Read the data in</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#run-stream-processing-app">Run stream processing app</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#write-the-data-out">Write the data out</a>
    </li>
        </ul>
    </li>
    </ul>
                </li>
    </ul>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Fin serv</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../fin-serv/">Description</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Healthcare</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../healthcare/">Description</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Retail</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../retail/">Description</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="#">Inventory</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../retail/inventory/">Real-time Inventory</a>
                </li>
    </ul>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Security</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../security/">Description</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Shared</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../shared/ccloud_setup/">Ccloud setup</a>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">ksqlDB Recipes</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Customer 360 &raquo;</li>
        
      
        
          <li>Clickstream &raquo;</li>
        
      
    
    <li>Clickstream Data Analysis</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  
  <hr/>
</div>

          <div role="main">
            <div class="section">
              
                <h1 id="clickstream-data-analysis">Clickstream Data Analysis</h1>
<h2 id="what-is-it">What is it?</h2>
<p>Analyzing clickstream data enables businesses to understand the behavior of its online users, for example:</p>
<ul>
<li>User activity over a given time frame: how many webpages are users viewing</li>
<li>Requests that end in error, over a given threshold (e.g., 404 HTTP codes)</li>
<li>Where the requests are coming from geographically in a given window of time</li>
<li>How long users are interacting with the site (user sessions)</li>
</ul>
<p><img alt="grafana" src="../../img/clickstream.png" /></p>
<h2 id="cut-to-the-code">Cut to the code</h2>
<p><img alt="launch" src="../../img/launch.png" /></p>
<pre><code class="language-sql">-- Stream of HTTP codes
CREATE SOURCE CONNECTOR datagen_clickstream_codes WITH (
  'connector.class'          = 'DatagenSource',
  'kafka.topic'              = 'clickstream_codes',
  'quickstart'               = 'clickstream_codes',
  'maxInterval'              = '20',
  'format'                   = 'json',
  'key.converter'            = 'org.apache.kafka.connect.converters.IntegerConverter');

-- Stream of users
CREATE SOURCE CONNECTOR datagen_clickstream_users WITH (
  'connector.class'          = 'DatagenSource',
  'kafka.topic'              = 'clickstream_users',
  'quickstart'               = 'clickstream_users',
  'maxInterval'              = '10',
  'format'                   = 'json',
  'key.converter'            = 'org.apache.kafka.connect.converters.IntegerConverter');

-- Stream of per-user session information
CREATE SOURCE CONNECTOR datagen_clickstream WITH (
  'connector.class'          = 'DatagenSource',
  'kafka.topic'              = 'clickstream',
  'quickstart'               = 'clickstream',
  'maxInterval'              = '30',
  'format'                   = 'json');

---------------------------------------------------------------------------------------------------
-- Register sources:
---------------------------------------------------------------------------------------------------
-- stream of user clicks:
CREATE STREAM clickstream (
        _time bigint,
        time varchar,
        ip varchar,
        request varchar,
        status int,
        userid int,
        bytes bigint,
        agent varchar
    ) with (
        kafka_topic = 'clickstream',
        value_format = 'json'
    );

-- error code lookup table:
CREATE TABLE clickstream_codes (
        code int primary key,
        definition varchar
    ) with (
        kafka_topic = 'clickstream_codes',
        value_format = 'json'
    );

-- users lookup table:
CREATE TABLE WEB_USERS (
        user_id int primary key,
        registered_At BIGINT,
        username varchar,
        first_name varchar,
        last_name varchar,
        city varchar,
        level varchar
    ) with (
        kafka_topic = 'clickstream_users',
        value_format = 'json'
    );

---------------------------------------------------------------------------------------------------
-- Build materialized stream views:
---------------------------------------------------------------------------------------------------

-- enrich click-stream with more user information:
CREATE STREAM USER_CLICKSTREAM AS
    SELECT
        userid,
        u.username,
        ip,
        u.city,
        request,
        status,
        bytes
    FROM clickstream c
        LEFT JOIN web_users u ON c.userid = u.user_id;

-- Enrich click-stream with more information about error codes:
CREATE STREAM ENRICHED_ERROR_CODES AS
    SELECT
        code,
        definition
    FROM clickstream
        LEFT JOIN clickstream_codes ON clickstream.status = clickstream_codes.code;

---------------------------------------------------------------------------------------------------
-- Build materialized table views:
---------------------------------------------------------------------------------------------------

-- Per-userId tables -----------------------------------------------------------------------------

-- Table of events per minute for each user:
CREATE table events_per_min AS
    SELECT
        userid as k1,
        AS_VALUE(userid) as userid,
        WINDOWSTART as EVENT_TS,
        count(*) AS events
    FROM clickstream window TUMBLING (size 60 second)
    GROUP BY userid;

-- Table of html pages per minute for each user:
CREATE TABLE pages_per_min AS
    SELECT
        userid as k1,
        AS_VALUE(userid) as userid,
        WINDOWSTART as EVENT_TS,
        count(*) AS pages
    FROM clickstream WINDOW HOPPING (size 60 second, advance by 5 second)
    WHERE request like '%html%'
    GROUP BY userid;

-- Per-username tables ----------------------------------------------------------------------------

-- User sessions table - 30 seconds of inactivity expires the session
-- Table counts number of events within the session
CREATE TABLE CLICK_USER_SESSIONS AS
    SELECT
        username as K,
        AS_VALUE(username) as username,
        WINDOWEND as EVENT_TS,
        count(*) AS events
    FROM USER_CLICKSTREAM window SESSION (30 second)
    GROUP BY username;

-- Per-status tables ------------------------------------------------------------------------------

-- number of errors per min, using 'HAVING' Filter to show ERROR codes &gt; 400 where count &gt; 5
CREATE TABLE ERRORS_PER_MIN_ALERT AS
    SELECT
        status as k1,
        AS_VALUE(status) as status,
        WINDOWSTART as EVENT_TS,
        count(*) AS errors
    FROM clickstream window HOPPING (size 60 second, advance by 20 second)
    WHERE status &gt; 400
    GROUP BY status
    HAVING count(*) &gt; 5 AND count(*) is not NULL;

-- number of errors per min
CREATE TABLE ERRORS_PER_MIN AS
    SELECT
        status as k1,
        AS_VALUE(status) as status,
        WINDOWSTART as EVENT_TS,
        count(*) AS errors
    FROM clickstream window HOPPING (size 60 second, advance by 5  second)
    WHERE status &gt; 400
    GROUP BY status;

-- Per-error code tables --------------------------------------------------------------------------

-- Enriched error codes table:
-- Aggregate (count&amp;groupBy) using a TABLE-Window
CREATE TABLE ENRICHED_ERROR_CODES_COUNT WITH (key_format='json') AS
    SELECT
        code as k1,
        definition as K2,
        AS_VALUE(code) as code,
        WINDOWSTART as EVENT_TS,
        AS_VALUE(definition) as definition,
        COUNT(*) AS count
    FROM ENRICHED_ERROR_CODES WINDOW TUMBLING (size 30 second)
    GROUP BY code, definition
    HAVING COUNT(*) &gt; 1;

-- Enriched user details table:
-- Aggregate (count&amp;groupBy) using a TABLE-Window
CREATE TABLE USER_IP_ACTIVITY WITH (key_format='json') AS
    SELECT
        username as k1,
        ip as k2,
        city as k3,
        AS_VALUE(username) as username,
        WINDOWSTART as EVENT_TS,
        AS_VALUE(ip) as ip,
        AS_VALUE(city) as city,
        COUNT(*) AS count
    FROM USER_CLICKSTREAM WINDOW TUMBLING (size 60 second)
    GROUP BY username, ip, city
    HAVING COUNT(*) &gt; 1;

-- Send data to Elasticsearch
CREATE SINK CONNECTOR analyzed_clickstream WITH (
  'connector.class'          = 'ElasticsearchSink',
  'name'                     = 'elasticsearch-connector',
  'input.data.format'        = 'JSON',
  'kafka.api.key'            = '&lt;my-kafka-api-key&gt;',
  'kafka.api.secret'         = '&lt;my-kafka-api-secret&gt;',
  'topics'                   = 'USER_IP_ACTIVITY, ENRICHED_ERROR_CODES_COUNT',
  'connection.url'           = '&lt;elasticsearch-URI&gt;',
  'connection.user'          = '&lt;elasticsearch-username&gt;',
  'connection.password'      = '&lt;elasticsearch-password&gt;',
  'type.name'                = 'type.name=kafkaconnect',
  'key.ignore'               = 'true',
  'schema.ignore'            = 'true'
);
</code></pre>
<h2 id="launch-step-by-step">Launch Step-by-Step</h2>
<h3 id="setup-your-environment">Setup your Environment</h3>
<ol>
<li>
<p>Sign up for <a href="https://www.confluent.io/confluent-cloud/tryfree/">Confluent Cloud</a>, a fully-managed Apache Kafka service.</p>
</li>
<li>
<p>After you log in to Confluent Cloud, click on <code>Add cloud environment</code> and name the environment <code>learn-kafka</code>. Using a new environment keeps your learning resources separate from your other Confluent Cloud resources.</p>
</li>
<li>
<p>From the <code>Billing &amp; payment</code> section in the Menu, apply the promo code <code>C50INTEG</code> to receive an additional $50 free usage on Confluent Cloud (<a href="https://www.confluent.io/confluent-cloud-promo-disclaimer">details</a>).</p>
</li>
<li>
<p>Click on <a href="https://confluent.cloud/learn">LEARN</a> and follow the instructions to launch a Kafka cluster and to enable Schema Registry.</p>
</li>
</ol>
<h3 id="read-the-data-in">Read the data in</h3>
<p>This recipe creates simulated data with the <code>Datagen</code> connector.</p>
<pre><code class="language-sql">-- Stream of HTTP codes
CREATE SOURCE CONNECTOR datagen_clickstream_codes WITH (
  'connector.class'          = 'DatagenSource',
  'kafka.topic'              = 'clickstream_codes',
  'quickstart'               = 'clickstream_codes',
  'maxInterval'              = '20',
  'format'                   = 'json',
  'key.converter'            = 'org.apache.kafka.connect.converters.IntegerConverter');

-- Stream of users
CREATE SOURCE CONNECTOR datagen_clickstream_users WITH (
  'connector.class'          = 'DatagenSource',
  'kafka.topic'              = 'clickstream_users',
  'quickstart'               = 'clickstream_users',
  'maxInterval'              = '10',
  'format'                   = 'json',
  'key.converter'            = 'org.apache.kafka.connect.converters.IntegerConverter');

-- Stream of per-user session information
CREATE SOURCE CONNECTOR datagen_clickstream WITH (
  'connector.class'          = 'DatagenSource',
  'kafka.topic'              = 'clickstream',
  'quickstart'               = 'clickstream',
  'maxInterval'              = '30',
  'format'                   = 'json');
</code></pre>
<p>Optional: to simulate a real-world scenario where user sessions aren't just always open but do close after some time, you can pause and resume the <code>DATAGEN_CLICKSTREAM</code> connector.</p>
<h3 id="run-stream-processing-app">Run stream processing app</h3>
<p>Now you can process the data in a variety of ways, by enriching the clickstream data with user information, analyze errors, aggregate data into windows of time, etc.</p>
<pre><code class="language-sql">---------------------------------------------------------------------------------------------------
-- Register sources:
---------------------------------------------------------------------------------------------------
-- stream of user clicks:
CREATE STREAM clickstream (
        _time bigint,
        time varchar,
        ip varchar,
        request varchar,
        status int,
        userid int,
        bytes bigint,
        agent varchar
    ) with (
        kafka_topic = 'clickstream',
        value_format = 'json'
    );

-- error code lookup table:
CREATE TABLE clickstream_codes (
        code int primary key,
        definition varchar
    ) with (
        kafka_topic = 'clickstream_codes',
        value_format = 'json'
    );

-- users lookup table:
CREATE TABLE WEB_USERS (
        user_id int primary key,
        registered_At BIGINT,
        username varchar,
        first_name varchar,
        last_name varchar,
        city varchar,
        level varchar
    ) with (
        kafka_topic = 'clickstream_users',
        value_format = 'json'
    );

---------------------------------------------------------------------------------------------------
-- Build materialized stream views:
---------------------------------------------------------------------------------------------------

-- enrich click-stream with more user information:
CREATE STREAM USER_CLICKSTREAM AS
    SELECT
        userid,
        u.username,
        ip,
        u.city,
        request,
        status,
        bytes
    FROM clickstream c
        LEFT JOIN web_users u ON c.userid = u.user_id;

-- Enrich click-stream with more information about error codes:
CREATE STREAM ENRICHED_ERROR_CODES AS
    SELECT
        code,
        definition
    FROM clickstream
        LEFT JOIN clickstream_codes ON clickstream.status = clickstream_codes.code;

---------------------------------------------------------------------------------------------------
-- Build materialized table views:
---------------------------------------------------------------------------------------------------

-- Per-userId tables -----------------------------------------------------------------------------

-- Table of events per minute for each user:
CREATE table events_per_min AS
    SELECT
        userid as k1,
        AS_VALUE(userid) as userid,
        WINDOWSTART as EVENT_TS,
        count(*) AS events
    FROM clickstream window TUMBLING (size 60 second)
    GROUP BY userid;

-- Table of html pages per minute for each user:
CREATE TABLE pages_per_min AS
    SELECT
        userid as k1,
        AS_VALUE(userid) as userid,
        WINDOWSTART as EVENT_TS,
        count(*) AS pages
    FROM clickstream WINDOW HOPPING (size 60 second, advance by 5 second)
    WHERE request like '%html%'
    GROUP BY userid;

-- Per-username tables ----------------------------------------------------------------------------

-- User sessions table - 30 seconds of inactivity expires the session
-- Table counts number of events within the session
CREATE TABLE CLICK_USER_SESSIONS AS
    SELECT
        username as K,
        AS_VALUE(username) as username,
        WINDOWEND as EVENT_TS,
        count(*) AS events
    FROM USER_CLICKSTREAM window SESSION (30 second)
    GROUP BY username;

-- Per-status tables ------------------------------------------------------------------------------

-- number of errors per min, using 'HAVING' Filter to show ERROR codes &gt; 400 where count &gt; 5
CREATE TABLE ERRORS_PER_MIN_ALERT AS
    SELECT
        status as k1,
        AS_VALUE(status) as status,
        WINDOWSTART as EVENT_TS,
        count(*) AS errors
    FROM clickstream window HOPPING (size 60 second, advance by 20 second)
    WHERE status &gt; 400
    GROUP BY status
    HAVING count(*) &gt; 5 AND count(*) is not NULL;

-- number of errors per min
CREATE TABLE ERRORS_PER_MIN AS
    SELECT
        status as k1,
        AS_VALUE(status) as status,
        WINDOWSTART as EVENT_TS,
        count(*) AS errors
    FROM clickstream window HOPPING (size 60 second, advance by 5  second)
    WHERE status &gt; 400
    GROUP BY status;

-- Per-error code tables --------------------------------------------------------------------------

-- Enriched error codes table:
-- Aggregate (count&amp;groupBy) using a TABLE-Window
CREATE TABLE ENRICHED_ERROR_CODES_COUNT WITH (key_format='json') AS
    SELECT
        code as k1,
        definition as K2,
        AS_VALUE(code) as code,
        WINDOWSTART as EVENT_TS,
        AS_VALUE(definition) as definition,
        COUNT(*) AS count
    FROM ENRICHED_ERROR_CODES WINDOW TUMBLING (size 30 second)
    GROUP BY code, definition
    HAVING COUNT(*) &gt; 1;

-- Enriched user details table:
-- Aggregate (count&amp;groupBy) using a TABLE-Window
CREATE TABLE USER_IP_ACTIVITY WITH (key_format='json') AS
    SELECT
        username as k1,
        ip as k2,
        city as k3,
        AS_VALUE(username) as username,
        WINDOWSTART as EVENT_TS,
        AS_VALUE(ip) as ip,
        AS_VALUE(city) as city,
        COUNT(*) AS count
    FROM USER_CLICKSTREAM WINDOW TUMBLING (size 60 second)
    GROUP BY username, ip, city
    HAVING COUNT(*) &gt; 1;
</code></pre>
<h3 id="write-the-data-out">Write the data out</h3>
<p>After processing the data, send it to Elasticsearch.</p>
<pre><code class="language-sql">-- Send data to Elasticsearch
CREATE SINK CONNECTOR analyzed_clickstream WITH (
  'connector.class'          = 'ElasticsearchSink',
  'name'                     = 'elasticsearch-connector',
  'input.data.format'        = 'JSON',
  'kafka.api.key'            = '&lt;my-kafka-api-key&gt;',
  'kafka.api.secret'         = '&lt;my-kafka-api-secret&gt;',
  'topics'                   = 'USER_IP_ACTIVITY, ENRICHED_ERROR_CODES_COUNT',
  'connection.url'           = '&lt;elasticsearch-URI&gt;',
  'connection.user'          = '&lt;elasticsearch-username&gt;',
  'connection.password'      = '&lt;elasticsearch-password&gt;',
  'type.name'                = 'type.name=kafkaconnect',
  'key.ignore'               = 'true',
  'schema.ignore'            = 'true'
);
</code></pre>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../../fin-serv/" class="btn btn-neutral float-right" title="Description">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../" class="btn btn-neutral" title="Description"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../../fin-serv/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme_extra.js" defer></script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>

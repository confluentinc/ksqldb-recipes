{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to ksqlDB Recipes","title":"ksqlDB Recipes"},{"location":"#welcome-to-ksqldb-recipes","text":"","title":"Welcome to ksqlDB Recipes"},{"location":"security/recipe1/","text":"Recipe 1 Overview The use case is... Cut to the code -- Create source connector CREATE SOURCE CONNECTOR source_conn WITH ... ; --Setup CREATE STREAM FOOBAR WITH ....; -- Create sink connector CREATE SINK CONNECTOR sink_conn WITH ... ; Launch the Recipe Setup your Environment Sign up for Confluent Cloud , a fully-managed Apache Kafka service. After you log in to Confluent Cloud, click on Add cloud environment and name the environment learn-kafka . Using a new environment keeps your learning resources separate from your other Confluent Cloud resources. From the Billing & payment section in the Menu, apply the promo code C50INTEG to receive an additional $50 free usage on Confluent Cloud ( details ). Click on LEARN and follow the instructions to launch a Kafka cluster and to enable Schema Registry. Read the data in This recipe uses blah blah connector. It assumes you have setup foobar. -- Create source connector CREATE SOURCE CONNECTOR source_conn WITH ... ; Run stream processing app Translate and filter all the things. --Setup CREATE STREAM FOOBAR WITH ....; Write the data out Post-processing, send the data to this DB. -- Create sink connector CREATE SINK CONNECTOR sink_conn WITH ... ;","title":"Recipe 1"},{"location":"security/recipe1/#recipe-1","text":"","title":"Recipe 1"},{"location":"security/recipe1/#overview","text":"The use case is...","title":"Overview"},{"location":"security/recipe1/#cut-to-the-code","text":"-- Create source connector CREATE SOURCE CONNECTOR source_conn WITH ... ; --Setup CREATE STREAM FOOBAR WITH ....; -- Create sink connector CREATE SINK CONNECTOR sink_conn WITH ... ;","title":"Cut to the code"},{"location":"security/recipe1/#launch-the-recipe","text":"","title":"Launch the Recipe"},{"location":"security/recipe1/#setup-your-environment","text":"Sign up for Confluent Cloud , a fully-managed Apache Kafka service. After you log in to Confluent Cloud, click on Add cloud environment and name the environment learn-kafka . Using a new environment keeps your learning resources separate from your other Confluent Cloud resources. From the Billing & payment section in the Menu, apply the promo code C50INTEG to receive an additional $50 free usage on Confluent Cloud ( details ). Click on LEARN and follow the instructions to launch a Kafka cluster and to enable Schema Registry.","title":"Setup your Environment"},{"location":"security/recipe1/#read-the-data-in","text":"This recipe uses blah blah connector. It assumes you have setup foobar. -- Create source connector CREATE SOURCE CONNECTOR source_conn WITH ... ;","title":"Read the data in"},{"location":"security/recipe1/#run-stream-processing-app","text":"Translate and filter all the things. --Setup CREATE STREAM FOOBAR WITH ....;","title":"Run stream processing app"},{"location":"security/recipe1/#write-the-data-out","text":"Post-processing, send the data to this DB. -- Create sink connector CREATE SINK CONNECTOR sink_conn WITH ... ;","title":"Write the data out"},{"location":"shared/ccloud_setup/","text":"Sign up for Confluent Cloud , a fully-managed Apache Kafka service. After you log in to Confluent Cloud, click on Add cloud environment and name the environment learn-kafka . Using a new environment keeps your learning resources separate from your other Confluent Cloud resources. From the Billing & payment section in the Menu, apply the promo code C50INTEG to receive an additional $50 free usage on Confluent Cloud ( details ). Click on LEARN and follow the instructions to launch a Kafka cluster and to enable Schema Registry.","title":"Ccloud setup"}]}